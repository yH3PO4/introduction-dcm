\chapter{パラメータ推定}\label{ch:parameter_est}

\ref{ch:utility}章で立式した効用の値を求めるには、未知のパラメータである $\beta_{time}, \beta_{cost}, \beta_{S,age}, \ldots$ を求めなければいけません。これらの未知パラメータを、データを使って推定することを\textbf{パラメータ推定}といいます。

パラメータ推定では、パラメータの\textbf{尤度}（もっともらしさ）が最大になるようにパラメータを決定します。離散選択モデルの場合、\textbf{モデルから計算される各選択肢の選択確率が、実際の各選択肢の選択確率にできるだけ近くなるように}すればよいです。

\section{パラメータ推定に用いるデータ}\label{sec:data}

実際の各選択肢の選択確率は、交通分野の場合、以下のようなデータを組み合わせて用いることで得ることができます。

\begin{description}
    \item[LOSデータ]交通サービス水準。所要時間や運賃など交通手段に固有の特性を表すデータ。
    \item[RP調査によるデータ]人々がある地点から別の地点へ実際に移動する際に、いつ・どこへ・どんな交通手段で・何のために移動したのかの情報を収集したデータ。個人の属性の情報もセットで記録する。
    \begin{description}
        \item[PT（パーソントリップ）データ] RP調査のうち、平均的な一日の行動についてアンケートによって収集したデータ。
        \item[PP（プローブパーソン）データ] RP調査のうち、GPS等を用いて実際の行動記録を収集して整理したデータ。
    \end{description}
    \item[SP調査によるアンケートデータ]様々な条件を仮定したときにどんな移動をすることを選ぶかの希望を、アンケートによって収集したデータ。実際の行動に基づかないためやや信頼性が落ちる代わりに、未来の交通手段などを想定したアンケートをすることができる。個人の属性の情報もセットで記録する。LOSに相当する、どの選択肢ならどんな条件で使えるかという情報がアンケート内に含まれている。
\end{description}


これらのデータから、交通手段に固有の特性や個人の属性といった説明変数になりえる値と、実際にどの選択肢が選ばれたかという結果がわかります。パラメータ推定によってモデルを実際の選択結果に近づけ、できたモデルをもとに新たな条件ではどの選択肢がどれだけの確率で選択できるかを推定する、というのがモデルの活用の流れです。

\section{尤度}\label{sec:likelihood}

MNLにおける尤度の求め方を示します。

$M$ 人が $N$ 個の選択肢の中から独立に選択行動をします。$i$ 番目の人にとっての説明変数が $\bm{x_i}$ である\footnote{説明変数は複数個ありうるのでベクトルで表記します。ここでは、交通手段の特性由来の説明変数も、個人の属性由来の説明変数も一つにまとめています。}とき、選択肢 $y_i$ が選ばれる確率を $P(y_i;\bm{x_i})$ と書くことにします。

このとき $1,2,\ldots,M$ 番目の人が それぞれ $y_1,y_2,\ldots,y_M (1 \le y_i \le N)$ の選択肢を選択する同時確率は、各人の選択行動が独立であることから、式(\ref{eq:joint_prob})のように表されます。

\begin{equation}
    \label{eq:joint_prob}
    P(y_1;\bm{x_1},y_2;\bm{x_2},\ldots,y_M;\bm{x_M}) = P(y_1;\bm{x_1})P(y_2;\bm{x_2}) \cdots P(y_M;\bm{x_M}) = \prod_{i=1}^M P(y_i;\bm{x_i})
\end{equation}

なお、MNLでは式(\ref{eq:joint_prob})の値は次の式(\ref{eq:joint_prob_mnl})のように書けます。

\begin{equation}
    \label{eq:joint_prob_mnl}
    \prod_{i=1}^M\frac{\exp(V_{y_i})}{\sum_{j=1}^N \exp(V_j)}
\end{equation}

効用の確定項 $V$ は、\ref{ch:utility}章で立式したように、説明変数 $\bm x$ と未知パラメータ $\bm\beta$ \footnote{未知パラメータも複数あるのでベクトルで表記します。}によって決まる値でした。

ところで、$i$ 番目の人が $y_i$ を選ぶという事象はすでに確定していますし、各人・各選択肢の説明変数も分かっています。分かっていない値は未知パラメータです。そこで\textbf{尤度関数} $L(\bm\beta)$ を、式の形は変えずに次のように定義します。

\begin{equation}
    \label{eq:likelihood}
    L(\bm\beta) \coloneq \prod_{i=1}^M P(y_i;\bm{x_i}) = \prod_{i=1}^M\frac{\exp(V_{y_i})}{\sum_{j=1}^N \exp(V_j)}
\end{equation}

すると、この尤度関数を最大化することは、$\bm\beta$ を変化させることによって $y_1,y_2,\ldots,x_M$ の選択肢が選択される同時確率を最大化することにほかなりません。したがって、尤度関数を最大化するような $\bm\beta$ と、$\bm\beta$ によって計算される効用の確定項 $V$ は、実際の現象をもっともうまく表現しているということができます。

このように、尤度を最大化するようなパラメータを真のパラメータであるとする手法のことを\textbf{最尤推定法}といいます。

ある条件においてどの選択肢がどのくらいの確率で選ばれるのかを推定する、という問題は、最終的に関数を最大化する問題に帰着されました。関数の最大化問題は、古くから数理最適化の分野で研究が進められ、強力なソルバーが多数提供されています。よって、この関数の最大化問題には深く立ち入らず、実装上はRやPythonのSciPyで提供されている\textbf{最適化ライブラリ}を使用して解きます。

ライブラリに投げる前に、2点注意するべきことがあります。1つは尤度を直接最大化する代わりに次項で述べる\textbf{対数尤度}を最大化すること、もう1つは最尤推定法によって未知パラメータが一意に定まるように効用を立式することです。

\subsection{対数尤度}\label{ssec:log_likelihood}

対数尤度とは、尤度の対数を取った値です。尤度 $L(\bm\beta) = \prod_{i=1}^M P(y_i;\bm{x_i})$ は、1より小さい値を大量に掛け合わせて得られるため、非常に小さな値をとります。このため、プログラムで尤度を直接求めると、誤差によって $0$ に丸められてしまう恐れがあります。

そこで、尤度を最大化する代わりに尤度の対数を取った値を最大化することを考えます。対数尤度 $LL(\bm\beta)$ は次の式(\ref{eq:log_likelihood})で定義されます。

\begin{equation}
    \label{eq:log_likelihood}
    LL(\bm\beta) \coloneq\log L(\bm\beta) = \sum_{i=1}^M \log P(y_i;\bm{x_i})
\end{equation}

対数尤度の値は、選択確率が非常に小さくなるような選択肢が選ばれていない限りは問題なく計算できます。

\subsection{未知パラメータが一意に定まるような効用式}\label{ssec:est_unique}

尤度が最大となるようなパラメータの組が無限通りある、という状況が生じてしまうと、尤度関数の最大化が収束しなくなりパラメータ推定に失敗してしまいます。

例えば、効用の確定項を下の式(\ref{eq:utility_bad})のように立式すると、パラメータ推定に失敗します。

\begin{equation}
    \label{eq:utility_bad}
    \begin{aligned}
        V_S & =\beta_{time}x_{S,time}+\beta_{cost} x_{S,cost}+\beta_{S,age}x_{age}+\beta_S \\
        V_B & =\beta_{time}x_{B,time}+\beta_{cost} x_{B,cost}+\beta_{B,age}x_{age}+\beta_B \\
        V_P & =\beta_{time}x_{P,time}+\beta_{cost} x_{P,cost}+\beta_{P,age}x_{age}+\beta_P
    \end{aligned}
\end{equation}

「説明変数を掛けないパラメータ」を全ての選択肢につけてはいけません。次の式(\ref{eq:utility_good})のように，\textbf{「説明変数を掛けないパラメータ」の数は、選択肢の数よりも1少なくなるようにする}必要があります。

\begin{equation}
    \label{eq:utility_good}
    \begin{aligned}
        V_S & =\beta_{time}x_{S,time}+\beta_{cost} x_{S,cost}+\beta_{S,age}x_{age}         \\
        V_B & =\beta_{time}x_{B,time}+\beta_{cost} x_{B,cost}+\beta_{B,age}x_{age}+\beta_B \\
        V_P & =\beta_{time}x_{P,time}+\beta_{cost} x_{P,cost}+\beta_{P,age}x_{age}+\beta_P
    \end{aligned}
\end{equation}

選択確率の式(\ref{eq:mnl})を見ればわかるように、選択確率は $V$ の値そのものではなく、$\exp(V)$ の値の\textbf{比}によって決まります。「説明変数を掛けないパラメータ」をすべての選択肢の効用式につけると、各選択肢の選択確率が同じになるような $(\beta_S, \beta_B, \beta_P)$ の値の組が無限通り存在することになってしまいます。説明変数を掛けないパラメータを一つ減らすことで自由度が下がり、この問題が解消されます。
